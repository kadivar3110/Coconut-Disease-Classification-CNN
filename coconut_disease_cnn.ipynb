{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Coconut Disease Classification & Diagnostic System\n",
                "### Classes: CCI_Caterpillars, CCI_Leaflets, Healthy_Leaves, WCLWD_DryingofLeaflets, WCLWD_Flaccidity, WCLWD_Yellowing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import zipfile\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from sklearn.utils.class_weight import compute_class_weight\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.preprocessing import image\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense,\n",
                "                                     Dropout, LayerNormalization, ZeroPadding2D)\n",
                "from tensorflow.keras.optimizers import Adam"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Extract Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = r\"d:\\New folder (2)\"\n",
                "extract_dir = os.path.join(data_dir, \"dataset\")\n",
                "\n",
                "zip_files = [\"CCI_Caterpillars.zip\", \"CCI_Leaflets.zip\", \"Healthy_Leaves.zip\",\n",
                "             \"WCLWD_DryingofLeaflets.zip\", \"WCLWD_Flaccidity.zip\", \"WCLWD_Yellowing.zip\"]\n",
                "\n",
                "if os.path.exists(extract_dir):\n",
                "    print(\"Dataset already extracted, skipping...\")\n",
                "else:\n",
                "    for z in zip_files:\n",
                "        zip_path = os.path.join(data_dir, z)\n",
                "        if os.path.exists(zip_path):\n",
                "            print(f\"Extracting {z}...\")\n",
                "            with zipfile.ZipFile(zip_path, 'r') as zf:\n",
                "                zf.extractall(extract_dir)\n",
                "    print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Check Class Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class_names = sorted(os.listdir(extract_dir))\n",
                "class_counts = [len(os.listdir(os.path.join(extract_dir, c))) for c in class_names]\n",
                "\n",
                "for name, count in zip(class_names, class_counts):\n",
                "    print(f\"{name}: {count} images\")\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.bar(class_names, class_counts, color='skyblue')\n",
                "plt.xticks(rotation=30, ha='right')\n",
                "plt.title('Class Distribution')\n",
                "plt.ylabel('Images')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "print(f\"Imbalance ratio: {max(class_counts)/min(class_counts):.1f}x\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "IMG_SIZE = 128\n",
                "BATCH_SIZE = 32\n",
                "\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1.0/255, validation_split=0.2,\n",
                "    horizontal_flip=True, vertical_flip=True,\n",
                "    rotation_range=30, zoom_range=0.2,\n",
                "    shear_range=0.2, width_shift_range=0.1, height_shift_range=0.1\n",
                ")\n",
                "val_datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)\n",
                "\n",
                "train_data = train_datagen.flow_from_directory(\n",
                "    extract_dir, target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE, class_mode='categorical', subset='training', shuffle=True\n",
                ")\n",
                "val_data = val_datagen.flow_from_directory(\n",
                "    extract_dir, target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE, class_mode='categorical', subset='validation', shuffle=False\n",
                ")\n",
                "\n",
                "num_classes = len(train_data.class_indices)\n",
                "CLASS_NAMES = list(train_data.class_indices.keys())\n",
                "print(f\"Classes: {train_data.class_indices}\")\n",
                "print(f\"Train: {train_data.samples} | Val: {val_data.samples}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Compute Class Weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "weights = compute_class_weight('balanced', classes=np.unique(train_data.classes), y=train_data.classes)\n",
                "class_weight = dict(zip(np.unique(train_data.classes), weights))\n",
                "\n",
                "print(\"Class Weights:\")\n",
                "for idx, name in enumerate(CLASS_NAMES):\n",
                "    print(f\"  {name}: {class_weight[idx]:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Build CNN + ANN Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = Sequential()\n",
                "\n",
                "# CNN Block 1\n",
                "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
                "model.add(LayerNormalization())\n",
                "model.add(ZeroPadding2D(padding=(1,1)))\n",
                "model.add(MaxPooling2D(pool_size=(2,2)))\n",
                "\n",
                "# CNN Block 2\n",
                "model.add(Conv2D(64, (3,3), activation='relu'))\n",
                "model.add(LayerNormalization())\n",
                "model.add(ZeroPadding2D(padding=(1,1)))\n",
                "model.add(MaxPooling2D(pool_size=(2,2)))\n",
                "\n",
                "# CNN Block 3\n",
                "model.add(Conv2D(128, (3,3), activation='relu'))\n",
                "model.add(LayerNormalization())\n",
                "model.add(ZeroPadding2D(padding=(1,1)))\n",
                "model.add(MaxPooling2D(pool_size=(2,2)))\n",
                "\n",
                "# Flatten + ANN\n",
                "model.add(Flatten())\n",
                "model.add(Dense(256, activation='relu'))\n",
                "model.add(Dropout(0.5))\n",
                "model.add(Dense(128, activation='relu'))\n",
                "model.add(Dropout(0.3))\n",
                "model.add(Dense(num_classes, activation='softmax'))\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Compile and Train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
                "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "history = model.fit(train_data, validation_data=val_data,\n",
                "                    epochs=25, class_weight=class_weight)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Plot Accuracy and Loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
                "ax1.plot(history.history['accuracy'], label='Train')\n",
                "ax1.plot(history.history['val_accuracy'], label='Val')\n",
                "ax1.set_title('Accuracy'); ax1.legend()\n",
                "ax2.plot(history.history['loss'], label='Train')\n",
                "ax2.plot(history.history['val_loss'], label='Val')\n",
                "ax2.set_title('Loss'); ax2.legend()\n",
                "plt.tight_layout(); plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Evaluate and Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "val_loss, val_acc = model.evaluate(val_data)\n",
                "print(f\"\\nValidation Accuracy: {val_acc*100:.2f}%\")\n",
                "print(f\"Validation Loss: {val_loss:.4f}\")\n",
                "\n",
                "model.save(os.path.join(data_dir, \"coconut_disease_model.h5\"))\n",
                "print(\"Model saved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 2: Industry-Grade Diagnostic System\n",
                "## 10. Disease Information"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DISEASE_INFO = {\n",
                "    'CCI_Caterpillars': {\n",
                "        'full_name': 'Coconut Caterpillar Infestation',\n",
                "        'description': 'Caterpillar attack causing leaf damage.',\n",
                "        'treatment': {\n",
                "            'Mild': 'Remove affected leaves. Apply neem oil spray.',\n",
                "            'Moderate': 'Apply Bt biopesticide. Remove damaged leaves.',\n",
                "            'Severe': 'Urgent chemical treatment. Consult agriculture officer.'\n",
                "        }\n",
                "    },\n",
                "    'CCI_Leaflets': {\n",
                "        'full_name': 'Caterpillar Infestation (Leaflets)',\n",
                "        'description': 'Caterpillar damage on leaflets.',\n",
                "        'treatment': {\n",
                "            'Mild': 'Cut damaged leaflets. Spray neem solution.',\n",
                "            'Moderate': 'Apply systemic insecticide. Monitor spread.',\n",
                "            'Severe': 'Mass spraying. Report to agriculture dept.'\n",
                "        }\n",
                "    },\n",
                "    'Healthy_Leaves': {\n",
                "        'full_name': 'Healthy Coconut Leaf',\n",
                "        'description': 'No disease detected.',\n",
                "        'treatment': {'Mild': 'No treatment needed.', 'Moderate': 'No treatment needed.', 'Severe': 'No treatment needed.'}\n",
                "    },\n",
                "    'WCLWD_DryingofLeaflets': {\n",
                "        'full_name': 'WCLWD - Drying of Leaflets',\n",
                "        'description': 'Leaf Wilt Disease causing drying.',\n",
                "        'treatment': {\n",
                "            'Mild': 'Remove dried leaflets. Apply NPK fertilizer.',\n",
                "            'Moderate': 'Root feeding. Apply fungicide.',\n",
                "            'Severe': 'Tree may need removal. Contact officer.'\n",
                "        }\n",
                "    },\n",
                "    'WCLWD_Flaccidity': {\n",
                "        'full_name': 'WCLWD - Leaf Flaccidity',\n",
                "        'description': 'Leaf Wilt Disease causing drooping.',\n",
                "        'treatment': {\n",
                "            'Mild': 'Improve drainage. Apply micronutrients.',\n",
                "            'Moderate': 'Root feeding treatment.',\n",
                "            'Severe': 'Quarantine tree. Consult pathologist.'\n",
                "        }\n",
                "    },\n",
                "    'WCLWD_Yellowing': {\n",
                "        'full_name': 'WCLWD - Yellowing',\n",
                "        'description': 'Leaf Wilt Disease causing yellowing.',\n",
                "        'treatment': {\n",
                "            'Mild': 'Apply magnesium sulfate and potash.',\n",
                "            'Moderate': 'Root feeding. Remove yellowed leaves.',\n",
                "            'Severe': 'Report to agriculture authority.'\n",
                "        }\n",
                "    }\n",
                "}\n",
                "print(\"Disease info loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Grad-CAM + Severity + Diagnosis Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# find last conv layer\n",
                "last_conv_name = None\n",
                "for layer in reversed(model.layers):\n",
                "    if 'conv2d' in layer.name.lower():\n",
                "        last_conv_name = layer.name\n",
                "        break\n",
                "print(f\"Last Conv2D: {last_conv_name}\")\n",
                "\n",
                "# store layer list for manual forward pass\n",
                "all_layers = model.layers\n",
                "\n",
                "\n",
                "def predict_with_gradcam(img_batch):\n",
                "    \"\"\"Single forward pass: prediction + Grad-CAM heatmap.\"\"\"\n",
                "    img_tensor = tf.cast(img_batch, tf.float32)\n",
                "    with tf.GradientTape() as tape:\n",
                "        x = img_tensor\n",
                "        conv_output = None\n",
                "        for layer in all_layers:\n",
                "            x = layer(x)\n",
                "            if layer.name == last_conv_name:\n",
                "                conv_output = x\n",
                "                tape.watch(conv_output)\n",
                "        pred_idx = tf.argmax(x[0])\n",
                "        class_score = x[:, pred_idx]\n",
                "    \n",
                "    grads = tape.gradient(class_score, conv_output)\n",
                "    pooled = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
                "    heatmap = conv_output[0] @ pooled[..., tf.newaxis]\n",
                "    heatmap = tf.squeeze(heatmap)\n",
                "    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-8)\n",
                "    return x.numpy(), heatmap.numpy()\n",
                "\n",
                "\n",
                "def make_overlay(img, heatmap, alpha=0.4):\n",
                "    \"\"\"Overlay heatmap on image.\"\"\"\n",
                "    h = np.uint8(255 * heatmap)\n",
                "    h = np.array(tf.image.resize(h[..., np.newaxis], (img.shape[0], img.shape[1])))[:,:,0]\n",
                "    h = h.astype(int)  # IMPORTANT: convert float to int for array indexing\n",
                "    jet = plt.colormaps['jet']\n",
                "    colored = jet(np.arange(256))[:, :3][h]\n",
                "    return np.clip(colored * alpha + img * (1 - alpha), 0, 1)\n",
                "\n",
                "\n",
                "def get_severity(confidence, heatmap):\n",
                "    \"\"\"Severity from confidence + heatmap.\"\"\"\n",
                "    affected = np.mean(heatmap > 0.3)\n",
                "    intensity = np.mean(heatmap[heatmap > 0.3]) if np.any(heatmap > 0.3) else 0.0\n",
                "    score = min((0.4*confidence) + (0.35*affected) + (0.25*intensity), 1.0)\n",
                "    if score < 0.35: return score, 'Mild'\n",
                "    elif score < 0.65: return score, 'Moderate'\n",
                "    else: return score, 'Severe'\n",
                "\n",
                "\n",
                "def diagnose_leaf(img_path, show_plot=True):\n",
                "    \"\"\"Full diagnosis: predict, Grad-CAM, severity, treatment.\"\"\"\n",
                "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
                "    img_arr = image.img_to_array(img) / 255.0\n",
                "    img_batch = np.expand_dims(img_arr, axis=0)\n",
                "    \n",
                "    preds, heatmap = predict_with_gradcam(img_batch)\n",
                "    idx = np.argmax(preds[0])\n",
                "    disease = CLASS_NAMES[idx]\n",
                "    conf = float(preds[0][idx])\n",
                "    \n",
                "    if disease == 'Healthy_Leaves':\n",
                "        sev_score, sev_label = 0.0, 'Healthy'\n",
                "    else:\n",
                "        sev_score, sev_label = get_severity(conf, heatmap)\n",
                "    \n",
                "    info = DISEASE_INFO[disease]\n",
                "    treat_key = 'Mild' if sev_label == 'Healthy' else sev_label\n",
                "    treatment = info['treatment'][treat_key]\n",
                "    \n",
                "    if show_plot:\n",
                "        overlay = make_overlay(img_arr, heatmap)\n",
                "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "        axes[0].imshow(img_arr); axes[0].set_title('Original'); axes[0].axis('off')\n",
                "        axes[1].imshow(heatmap, cmap='jet'); axes[1].set_title('Grad-CAM (Red=Affected)'); axes[1].axis('off')\n",
                "        axes[2].imshow(overlay); axes[2].set_title('Overlay'); axes[2].axis('off')\n",
                "        plt.suptitle(disease, fontsize=14, fontweight='bold')\n",
                "        plt.tight_layout(); plt.show()\n",
                "    \n",
                "    print(\"=\" * 55)\n",
                "    print(\"     COCONUT LEAF DIAGNOSTIC REPORT\")\n",
                "    print(\"=\" * 55)\n",
                "    print(f\"  Disease    : {info['full_name']}\")\n",
                "    print(f\"  Confidence : {conf*100:.1f}%\")\n",
                "    print(f\"  Severity   : {sev_label} ({sev_score:.2f})\")\n",
                "    print(f\"  Info       : {info['description']}\")\n",
                "    print(\"-\" * 55)\n",
                "    print(f\"  Treatment  : {treatment}\")\n",
                "    print(\"=\" * 55)\n",
                "    return {'disease': disease, 'confidence': conf, 'severity': sev_label}\n",
                "\n",
                "\n",
                "# quick test\n",
                "dummy = np.zeros((1, IMG_SIZE, IMG_SIZE, 3), dtype=np.float32)\n",
                "p, h = predict_with_gradcam(dummy)\n",
                "print(f\"Grad-CAM test passed! Heatmap: {h.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Test on All Classes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for class_name in CLASS_NAMES:\n",
                "    folder = os.path.join(extract_dir, class_name)\n",
                "    imgs = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg','.jpeg','.png','.bmp'))]\n",
                "    if imgs:\n",
                "        print(f\"\\nTesting: {class_name}\")\n",
                "        diagnose_leaf(os.path.join(folder, imgs[0]))\n",
                "        print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Batch Diagnosis Table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "\n",
                "print(f\"{'Image':<30} {'Predicted':<25} {'Conf':>6} {'Severity':>10}\")\n",
                "print(\"-\" * 75)\n",
                "for cn in CLASS_NAMES:\n",
                "    folder = os.path.join(extract_dir, cn)\n",
                "    imgs = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg','.jpeg','.png','.bmp'))]\n",
                "    for name in random.sample(imgs, min(2, len(imgs))):\n",
                "        r = diagnose_leaf(os.path.join(folder, name), show_plot=False)\n",
                "        print(f\"{name:<30} {r['disease']:<25} {r['confidence']*100:>5.1f}% {r['severity']:>9}\")\n",
                "print(\"-\" * 75)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}